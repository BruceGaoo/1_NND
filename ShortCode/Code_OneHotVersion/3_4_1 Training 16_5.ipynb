{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Lambda\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5                       # number of information bits\n",
    "N = 16                      # code length\n",
    "train_SNR_Eb = 1            # training-Eb/No\n",
    "\n",
    "epochs = 2**18           # number of learning epochs\n",
    "design = [80, 40, 20]      # each list entry defines the number of nodes in a layer\n",
    "batch_size = 2**k            # size of batches for calculation the gradient\n",
    "optimizer = 'adam'           \n",
    "loss = 'mse'                # or 'binary_crossentropy'\n",
    "\n",
    "train_SNR_Es = train_SNR_Eb + 10*np.log10(2 * k/N)      # training-SNR\n",
    "train_sigma = np.sqrt(1/(10**(train_SNR_Es/10)))    # training-sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_adder(a,b,c):\n",
    "    s = (a ^ b) ^ c\n",
    "    c = (a & b) | (c & (a ^ b))\n",
    "    return s,c\n",
    "\n",
    "def add_bool(a,b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError('arrays with different length')\n",
    "    k = len(a)\n",
    "    s = np.zeros(k,dtype=bool)\n",
    "    c = False\n",
    "    for i in reversed(range(0,k)):\n",
    "        s[i], c = full_adder(a[i],b[i],c)    \n",
    "    if c:\n",
    "        warnings.warn(\"Addition overflow!\")\n",
    "    return s\n",
    "\n",
    "def inc_bool(a):\n",
    "    k = len(a)\n",
    "    increment = np.hstack((np.zeros(k-1,dtype=bool), np.ones(1,dtype=bool)))\n",
    "    a = add_bool(a,increment)\n",
    "    return a\n",
    "\n",
    "def polar_design_awgn(N, k):\n",
    "    if N == 16:\n",
    "        idx = [0,  1,  2,  4,  8,  3,  5,  6,  9, 10, 12,  7, 11, 13, 14, 15]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    # select k best channels\n",
    "    idx = idx[N-k:]\n",
    "    \n",
    "    A = np.zeros(N, dtype=bool)\n",
    "    A[idx] = True\n",
    "    return A\n",
    "\n",
    "def polar_transform_iter(u):\n",
    "    N = len(u)\n",
    "    n = 1\n",
    "    x = np.copy(u)\n",
    "    stages = np.log2(N).astype(int)\n",
    "    for s in range(0,stages):\n",
    "        i = 0\n",
    "        while i < N:\n",
    "            for j in range(0,n):\n",
    "                idx = i+j\n",
    "                x[idx] = x[idx] ^ x[idx+n]\n",
    "            i=i+2*n\n",
    "        n=2*n\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all possible information words\n",
    "d = np.zeros((2**k,k),dtype=bool)\n",
    "for i in range(1,2**k):\n",
    "    d[i]= inc_bool(d[i-1])\n",
    "\n",
    "# Create sets of all possible codewords (codebook)\n",
    "A = polar_design_awgn(N, k)\n",
    "x = np.zeros((2**k, N),dtype=bool)\n",
    "u = np.zeros((2**k, N),dtype=bool)\n",
    "u[:,A] = d\n",
    "\n",
    "for i in range(0,2**k):\n",
    "    x[i] = polar_transform_iter(u[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulateBPSK(x):\n",
    "    return -2*x +1;\n",
    "\n",
    "def addNoise(x, sigma):\n",
    "    w = K.random_normal(K.shape(x), mean=0.0, stddev=sigma)\n",
    "    return x + w\n",
    "\n",
    "def return_output_shape(input_shape):  \n",
    "    return input_shape\n",
    "\n",
    "def compose_model(layers):\n",
    "    model = Sequential()\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "    return model\n",
    "\n",
    "def fe(y_true, y_pred):\n",
    "    tmp = tf.reduce_sum(tf.cast(tf.not_equal(y_true, tf.round(y_pred)), tf.int32), 1)\n",
    "    return tf.reduce_sum(tf.cast(tf.cast(tmp, tf.bool), tf.int32))\n",
    "\n",
    "def be(y_true, y_pred):\n",
    "    return tf.reduce_sum(tf.cast(tf.not_equal(y_true, tf.round(y_pred)), tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modulator\n",
    "modulator_layers = [Lambda(modulateBPSK, \n",
    "                          input_shape=(N,), output_shape=return_output_shape, name=\"modulator\")]\n",
    "\n",
    "modulator = compose_model(modulator_layers)\n",
    "modulator.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define noise\n",
    "noise_layers = [Lambda(addNoise, arguments={'sigma':train_sigma}, \n",
    "                       input_shape=(N,), output_shape=return_output_shape, name=\"noise\")]\n",
    "\n",
    "noise = compose_model(noise_layers)\n",
    "noise.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decoder \n",
    "decoder_layers = [Dense(design[0], activation='relu', input_shape=(N,))]\n",
    "for i in range(1,len(design)):\n",
    "    decoder_layers.append(Dense(design[i], activation='relu'))\n",
    "decoder_layers.append(Dense(k, activation='sigmoid'))\n",
    "\n",
    "decoder = compose_model(decoder_layers)\n",
    "decoder.compile(optimizer=optimizer, loss=loss, metrics=[fe, be])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_layers = modulator_layers + noise_layers + decoder_layers\n",
    "\n",
    "model = compose_model(model_layers)\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "modulator (Lambda)           (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "noise (Lambda)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                1360      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 5,525\n",
      "Trainable params: 5,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x, d, batch_size=batch_size, epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = 1000\n",
    "num_words = 100000      # multiple of test_batch\n",
    "\n",
    "ebn0_min = 0\n",
    "ebn0_max = 5\n",
    "points = 26\n",
    "ebn0 = np.linspace(ebn0_min, ebn0_max, points)\n",
    "\n",
    "bsum = np.zeros(points, dtype=np.float64)\n",
    "be = np.zeros(points, dtype=np.float64)\n",
    "fsum = np.zeros(points, dtype=np.float64)\n",
    "fe = np.zeros(points, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,points):\n",
    "    SNR = ebn0[i] + 10*np.log10(2 * k/N)\n",
    "    sigma = np.sqrt(1/(10**(SNR/10)))\n",
    "\n",
    "    for ii in range(0,np.round(num_words/test_batch).astype(int)):\n",
    "        \n",
    "        # Source\n",
    "        d_test = np.random.randint(0,2,size=(test_batch,k)) \n",
    "\n",
    "        # Encoder\n",
    "        x_test = np.zeros((test_batch, N),dtype=bool)\n",
    "        u_test = np.zeros((test_batch, N),dtype=bool)\n",
    "        u_test[:,A] = d_test\n",
    "\n",
    "        for iii in range(0,test_batch):\n",
    "            x_test[iii] = polar_transform_iter(u_test[iii])\n",
    "\n",
    "        # Modulator (BPSK)\n",
    "        s_test = -2*x_test + 1\n",
    "\n",
    "        # Channel (AWGN)\n",
    "        y_test = s_test + sigma*np.random.standard_normal(s_test.shape)\n",
    "\n",
    "        # Decoder\n",
    "        tmp1, tmp2 = decoder.evaluate(y_test, d_test, batch_size=test_batch, verbose=0)[1:]\n",
    "        fe[i] += tmp1\n",
    "        be[i] += tmp2\n",
    "        bsum[i] += test_batch*k\n",
    "        fsum[i] += test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ber = be/bsum\n",
    "fer = fe/fsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_map = np.loadtxt('map/polar/results_polar_map_{}_{}.txt'.format(N,k), delimiter=', ')\n",
    "sigma_map = result_map[:,0]\n",
    "bsum_map = result_map[:,1]\n",
    "be_map = result_map[:,2]\n",
    "fsum_map = result_map[:,3]\n",
    "fe_map = result_map[:,4]\n",
    "\n",
    "ebn0_map = 10*np.log10(1/(sigma_map**2)) - 10*np.log10(2 * k/N)\n",
    "ber_map = be_map/bsum_map\n",
    "fer_map = fe_map/fsum_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Bit-Error-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "legend = ['NN FER', 'NN BER', 'MAP FER', 'MAP BER']\n",
    "\n",
    "plt.plot(ebn0, fer, 'c') \n",
    "plt.plot(ebn0, ber, 'c--') \n",
    "plt.plot(ebn0_map, fer_map, 'r')\n",
    "plt.plot(ebn0_map, ber_map, 'r--') \n",
    "\n",
    "plt.legend(legend, loc=3)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$E_b/N_0$')\n",
    "plt.ylabel('FER / BER')    \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pd.Series(history.history['loss'])\n",
    "L.name = 'loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_NN = pd.DataFrame([ebn0, fer, ber]).T\n",
    "P_NN.columns = ['ebn0', 'fer', 'ber']\n",
    "P_MAP = pd.DataFrame([ebn0_map, fer_map, ber_map]).T\n",
    "P_MAP.columns = ['ebn0_map', 'fer_map', 'ber_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./result/model_16_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.to_csv('./result/LOSS_16_4.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_NN.to_csv('./result/P_NN_16_4.csv', header = True, index = False)\n",
    "P_MAP.to_csv('./result/P_MAP_16_4.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
